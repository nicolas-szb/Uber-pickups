{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best places to pick up customers in New-York City\n",
    "This projet is for Uber, taxi or all Vehicule Fore Hire drivers.\n",
    "This app allows drivers to target the best pickup areas in New-York City according to the date and the time.\n",
    "\n",
    "The user picks a date and some hours on the app which shows where are the areas with a lot of customers.\n",
    "\n",
    "---\n",
    "\n",
    "*Currently, this application only works with the month of April and the machine learning model is based on data from April 2014.*\n",
    "\n",
    "**New version:**\n",
    "- user can enters a list of hours in order to analyse the density evolution of customers in New-York City's boroughs\n",
    "\n",
    "**Improvements:**\n",
    "- add other months \n",
    "- deploy application with Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1:  Import libraires and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, GMapOptions\n",
    "from bokeh.plotting import gmap\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer dataset\n",
    "data_apr = pd.read_csv('uber-raw-data-apr14.csv')\n",
    "\n",
    "#zone_lookup = pd.read_csv('taxi-zone-lookup.csv')\n",
    "#zone_lookup.drop([55, 102, 103, 263], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Define all the needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a date and hour\n",
    "def choose_date_hour(date, hour):\n",
    "    \n",
    "    # Original dataset\n",
    "    data_apr.head(5)\n",
    "\n",
    "    # Split Time & Date\n",
    "    data_apr2 = np.array([data_apr['Date/Time'].str.split(' ')])\n",
    "    data_apr2 = pd.DataFrame(data_apr2.reshape(data_apr2.shape[1], data_apr2.shape[2]),\n",
    "                             columns=['Date', 'Time'])\n",
    "\n",
    "    # PSplit Date\n",
    "    data_apr3 = np.array([data_apr2['Date'].str.split('/')])\n",
    "    data_apr3 = pd.DataFrame(data_apr3.reshape(data_apr3.shape[1], data_apr3.shape[2]),\n",
    "                             columns=['Month', 'Day', 'Year']).astype(int)\n",
    "\n",
    "    # Concate all intermediate datasets\n",
    "    data_apr4 = pd.concat([data_apr.drop(['Date/Time'], axis=1), data_apr2.drop(['Date'],\n",
    "                                                                                axis=1), data_apr3], axis=1)\n",
    "\n",
    "    # Useless here\n",
    "    #data_apr4['Time'] = pd.to_datetime(data_apr4['Time'],format= '%H:%M:%S' ).dt.time\n",
    "\n",
    "    # Split dataset according to days in month\n",
    "    data_apr_day = [frame for data_apr_day,  frame in data_apr4.groupby('Day')]\n",
    "    # data_apr_day[3] = 4th day of April\n",
    "    \n",
    "    # April begins by 1 but index by 0\n",
    "    data_apr_day[date-1]\n",
    "    \n",
    "    # Clean dataset\n",
    "    data_apr_day_X = pd.DataFrame(data_apr_day[date-1].drop(['Base', 'Month', 'Year'], axis=1))\n",
    "    data_apr_day_X = data_apr_day_X.reset_index(drop=True)\n",
    "    \n",
    "    # Split Time\n",
    "    data_apr_day_X_2 = np.array([data_apr_day_X['Time'].str.split(':')])\n",
    "    data_apr_day_X_3 = pd.DataFrame(data_apr_day_X_2.reshape(data_apr_day_X_2.shape[1],\n",
    "                                                             data_apr_day_X_2.shape[2]),\n",
    "                                    columns=['Hours', 'Minutes', 'Seconds']).astype(int)\n",
    "\n",
    "\n",
    "    # Concate all intermediate datasets\n",
    "    data_apr_day_X_4 = pd.concat([data_apr_day_X.drop(['Time'], axis=1), data_apr_day_X_3], axis=1)\n",
    "    \n",
    "    # Split dataset according to hours in day\n",
    "    data_apr_day_X_hours = [frame for data_apr_day_X_hours,  frame in data_apr_day_X_4.groupby('Hours')]\n",
    "         \n",
    "    # new dataset, ready to shine\n",
    "    data_apr_day_X_hours[hour] = pd.DataFrame(data_apr_day_X_hours[hour].drop(['Seconds'], axis=1))\n",
    "    \n",
    "    return data_apr_day_X_hours[hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "def normalize(X):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    dataset_scaled = scaler.fit_transform(X.iloc[:,0:2])\n",
    "    \n",
    "    return dataset_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the best number of KMeans clusters by Silhouette method\n",
    "def silhouette_method(dataset_scaled):\n",
    "    \n",
    "    silhouette_list_kmeans = []\n",
    "    \n",
    "    # 15 is a subjective number. Search the number when the Elbow curve decrease would be the best way\n",
    "    for i in range(2,15):\n",
    "        kmeans_dataset_silhouette = KMeans(n_clusters=i, max_iter=300, n_init=10, n_jobs=-1, random_state=0)\n",
    "        kmeans_dataset_silhouette.fit(dataset_scaled[:,0:2])\n",
    "        silhouette_list_kmeans.append(silhouette_score(dataset_scaled[:,0:2], kmeans_dataset_silhouette.labels_))\n",
    "    \n",
    "    # Find the best number of clusters\n",
    "    index_best_nb_clusters_silhouette = np.where(silhouette_list_kmeans[1:15] == max(silhouette_list_kmeans[1:15]))\n",
    "\n",
    "    # 1 add 3 because :\n",
    "    # - silhouette_list begins at 2 clusters => +2\n",
    "    # - I dont keep the 1st index in silhouette_list because it's wrong => +1\n",
    "    best_n_clusters_silhouette = index_best_nb_clusters_silhouette[0][0]+3\n",
    "    \n",
    "    # Train the final model\n",
    "    kmeans_dataset_best = KMeans(n_clusters=best_n_clusters_silhouette, max_iter=300,\n",
    "                                 n_init=10, n_jobs=-1, random_state=0)\n",
    "    kmeans_dataset_best.fit(dataset_scaled[:,0:2])\n",
    "    dataset_scaled_clusters_kmeans_best = kmeans_dataset_best.predict(dataset_scaled[:,0:2])\n",
    "    \n",
    "    return kmeans_dataset_best, best_n_clusters_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all KMeans clusters on GMap\n",
    "def display_cluster_gmap(date, hour, best_n_clusters_silhouette, dataset, kmeans_dataset_best):\n",
    "    \n",
    "    X = dataset[['Lat','Lon']]\n",
    "    \n",
    "    cluster_X_kmeans = list()\n",
    "\n",
    "    #output_file(\"gmap.html\")\n",
    "\n",
    "    map_options = GMapOptions(lat=40.7128, lng=-74.0060, map_type=\"roadmap\", zoom=10)\n",
    "    p = gmap(\"AIzaSyB-E81VWnuGE2A9iXgHHI3lz5ZOvbRIN3A\",\n",
    "             map_options,\n",
    "             title=\"April {}, 2014 from {}H00 to {}H59, number of clusters: {}\".format(date, \n",
    "                                                                                       hour, \n",
    "                                                                                       hour, \n",
    "                                                                                       best_n_clusters_silhouette))\n",
    "    \n",
    "    for i in range(best_n_clusters_silhouette):\n",
    "        cluster_X_kmeans.append(ColumnDataSource(data=dict(lat=X[kmeans_dataset_best.labels_== i].iloc[:,0],\n",
    "                                                    lon=X[kmeans_dataset_best.labels_== i].iloc[:,1])))\n",
    "    \n",
    "        couleurs = [\"#\"+''.join([random.choice('0123456789ABCDEF') for i in range(6)])\n",
    "                    for j in range(best_n_clusters_silhouette)]\n",
    "\n",
    "        p.circle(x=\"lon\", y=\"lat\", size=6, color=couleurs[i], fill_alpha=1, source=cluster_X_kmeans[i])   \n",
    "\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3:  Create application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a date between 1 and 30: 2\n",
      "How many hours do you want to analyze? 3\n",
      "Choose a hour between 0 and 23: 0\n",
      "Choose a hour between 0 and 23: 10\n",
      "Choose a hour between 0 and 23: 17\n"
     ]
    }
   ],
   "source": [
    "# User chooses a date\n",
    "date = int(input(\"Choose a date between 1 and 30: \"))\n",
    "\n",
    "# user chooses the number of hours\n",
    "nb_hours = int(input(\"How many hours do you want to analyze? \"))\n",
    "\n",
    "list_hour = list()\n",
    "\n",
    "for i in range(nb_hours):\n",
    "    hour = int(input(\"Choose a hour between 0 and 23: \"))\n",
    "    list_hour.append(hour)\n",
    "    \n",
    "for hour in list_hour:\n",
    "\n",
    "    # Dataset created\n",
    "    dataset = choose_date_hour(date, hour)\n",
    "\n",
    "    # Dataset scaled\n",
    "    dataset_scaled = normalize(dataset)\n",
    "\n",
    "    # Parameters of KMeans models created\n",
    "    kmeans_dataset_best, best_n_clusters_silhouette = silhouette_method(dataset_scaled)\n",
    "\n",
    "    # Map and clusters display\n",
    "    display_cluster_gmap(date, hour, best_n_clusters_silhouette, dataset, kmeans_dataset_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
